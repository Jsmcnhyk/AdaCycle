Args in experiment:
Namespace(random_seed=2025, enable_visual=True, save_model=False, max_cycles=10, attn_dropout=0.15, wv='db1', kernel_size=None, m=3, is_training=1, model_id='ETTh1_96_720', model='AdaCycle', data='ETTh1', root_path='D:\\work\\datasets\\all_datasets\\/ETT-small/', data_path='ETTh1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=0, pred_len=720, cycle=0, use_revin=1, alpha=0.35, embed_type=0, enc_in=7, d_model=128, n_heads=8, d_ff=None, dropout=0.1, embed='timeF', activation='gelu', num_workers=0, itr=1, train_epochs=20, batch_size=64, patience=3, learning_rate=0.0009, des='test', loss='mse', lradj='type1', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1', inverse=False)
Use GPU: cuda:0
train 7825
val 2161
test 2161
>>>>>>>start training : ETTh1_96_720_AdaCycle_ETTh1_ftM_sl96_pl720_bz64_lr0.0009_ljtype1_al0.35_dm128_dp0.1_tk10_wvdb1_m3_dfNone_itr1>>>>>>>>>>>>>>>>>>>>>>>>>>
	iters: 100, epoch: 1 | loss: 3.6612120
	speed: 0.0267s/iter; left time: 62.5891s
Epoch: 1 cost time: 2.45996356010437
Epoch: 1, Steps: 122 | Train Loss: 3.7915007 Vali Loss: 4.7995093 Test Loss: 0.5404009
Validation loss decreased (inf --> 4.799509).  Saving model ...
Updating learning rate to 0.0009
	iters: 100, epoch: 2 | loss: 3.5558920
	speed: 0.0266s/iter; left time: 58.9693s
Epoch: 2 cost time: 2.1763172149658203
Epoch: 2, Steps: 122 | Train Loss: 3.6340939 Vali Loss: 4.6992525 Test Loss: 0.4621345
Validation loss decreased (4.799509 --> 4.699253).  Saving model ...
Updating learning rate to 0.00045
	iters: 100, epoch: 3 | loss: 3.5666993
	speed: 0.0264s/iter; left time: 55.3086s
Epoch: 3 cost time: 2.1774439811706543
Epoch: 3, Steps: 122 | Train Loss: 3.5713565 Vali Loss: 4.6738664 Test Loss: 0.4573171
Validation loss decreased (4.699253 --> 4.673866).  Saving model ...
Updating learning rate to 0.000225
	iters: 100, epoch: 4 | loss: 3.4884355
	speed: 0.0265s/iter; left time: 52.3004s
Epoch: 4 cost time: 2.1944997310638428
Epoch: 4, Steps: 122 | Train Loss: 3.5460671 Vali Loss: 4.6660737 Test Loss: 0.4495417
Validation loss decreased (4.673866 --> 4.666074).  Saving model ...
Updating learning rate to 0.0001125
	iters: 100, epoch: 5 | loss: 3.5507846
	speed: 0.0269s/iter; left time: 49.8912s
Epoch: 5 cost time: 2.2221858501434326
Epoch: 5, Steps: 122 | Train Loss: 3.5315405 Vali Loss: 4.6619608 Test Loss: 0.4400935
Validation loss decreased (4.666074 --> 4.661961).  Saving model ...
Updating learning rate to 5.625e-05
	iters: 100, epoch: 6 | loss: 3.5176859
	speed: 0.0263s/iter; left time: 45.6057s
Epoch: 6 cost time: 2.165318250656128
Epoch: 6, Steps: 122 | Train Loss: 3.5205732 Vali Loss: 4.6620858 Test Loss: 0.4402559
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.8125e-05
	iters: 100, epoch: 7 | loss: 3.5342460
	speed: 0.0267s/iter; left time: 42.8882s
Epoch: 7 cost time: 2.224141836166382
Epoch: 7, Steps: 122 | Train Loss: 3.5151038 Vali Loss: 4.6653897 Test Loss: 0.4407425
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.40625e-05
	iters: 100, epoch: 8 | loss: 3.3819337
	speed: 0.0263s/iter; left time: 39.1213s
Epoch: 8 cost time: 2.1867477893829346
Epoch: 8, Steps: 122 | Train Loss: 3.5123432 Vali Loss: 4.6636910 Test Loss: 0.4420896
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh1_96_720_AdaCycle_ETTh1_ftM_sl96_pl720_bz64_lr0.0009_ljtype1_al0.35_dm128_dp0.1_tk10_wvdb1_m3_dfNone_itr1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (2161, 720, 7) (2161, 720, 7)
test shape: (2161, 720, 7) (2161, 720, 7)
mse:0.440093457698822, mae:0.4508594870567322, rmse:0.6633954048156738, mape:0.7199552655220032
