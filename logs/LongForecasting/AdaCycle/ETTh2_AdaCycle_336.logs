Args in experiment:
Namespace(random_seed=2025, enable_visual=True, save_model=False, max_cycles=10, attn_dropout=0.15, wv='db1', kernel_size=None, m=2, is_training=1, model_id='ETTh2_96_336', model='AdaCycle', data='ETTh2', root_path='D:\\work\\datasets\\all_datasets\\/ETT-small/', data_path='ETTh2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=0, pred_len=336, cycle=0, use_revin=1, alpha=0.35, embed_type=0, enc_in=7, d_model=256, n_heads=8, d_ff=None, dropout=0.1, embed='timeF', activation='gelu', num_workers=0, itr=1, train_epochs=20, batch_size=64, patience=3, learning_rate=0.0002, des='test', loss='mse', lradj='type1', pct_start=0.3, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1', inverse=False)
Use GPU: cuda:0
train 8209
val 2545
test 2545
>>>>>>>start training : ETTh2_96_336_AdaCycle_ETTh2_ftM_sl96_pl336_bz64_lr0.0002_ljtype1_al0.35_dm256_dp0.1_tk10_wvdb1_m2_dfNone_itr1>>>>>>>>>>>>>>>>>>>>>>>>>>
	iters: 100, epoch: 1 | loss: 2.0484242
	speed: 0.0225s/iter; left time: 55.4404s
Epoch: 1 cost time: 2.040599822998047
Epoch: 1, Steps: 128 | Train Loss: 2.1357271 Vali Loss: 1.8739309 Test Loss: 0.4202300
Validation loss decreased (inf --> 1.873931).  Saving model ...
Updating learning rate to 0.0002
	iters: 100, epoch: 2 | loss: 2.0679693
	speed: 0.0221s/iter; left time: 51.4427s
Epoch: 2 cost time: 1.800602674484253
Epoch: 2, Steps: 128 | Train Loss: 2.0638104 Vali Loss: 1.8577281 Test Loss: 0.4093235
Validation loss decreased (1.873931 --> 1.857728).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 3 | loss: 2.1448860
	speed: 0.0219s/iter; left time: 48.2909s
Epoch: 3 cost time: 1.7870421409606934
Epoch: 3, Steps: 128 | Train Loss: 2.0362924 Vali Loss: 1.8503350 Test Loss: 0.4013018
Validation loss decreased (1.857728 --> 1.850335).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 4 | loss: 2.1791739
	speed: 0.0227s/iter; left time: 47.1287s
Epoch: 4 cost time: 1.865868091583252
Epoch: 4, Steps: 128 | Train Loss: 2.0160479 Vali Loss: 1.8410178 Test Loss: 0.3983956
Validation loss decreased (1.850335 --> 1.841018).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 5 | loss: 2.1866257
	speed: 0.0219s/iter; left time: 42.6282s
Epoch: 5 cost time: 1.787506341934204
Epoch: 5, Steps: 128 | Train Loss: 2.0031844 Vali Loss: 1.8374559 Test Loss: 0.3935773
Validation loss decreased (1.841018 --> 1.837456).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 6 | loss: 2.2147539
	speed: 0.0219s/iter; left time: 39.9670s
Epoch: 6 cost time: 1.792241096496582
Epoch: 6, Steps: 128 | Train Loss: 1.9963201 Vali Loss: 1.8375051 Test Loss: 0.3969004
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-06
	iters: 100, epoch: 7 | loss: 2.0681293
	speed: 0.0217s/iter; left time: 36.6854s
Epoch: 7 cost time: 1.7879343032836914
Epoch: 7, Steps: 128 | Train Loss: 1.9936375 Vali Loss: 1.8359789 Test Loss: 0.3962950
Validation loss decreased (1.837456 --> 1.835979).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 8 | loss: 2.2665935
	speed: 0.0218s/iter; left time: 34.1568s
Epoch: 8 cost time: 1.7838952541351318
Epoch: 8, Steps: 128 | Train Loss: 1.9916424 Vali Loss: 1.8367722 Test Loss: 0.3966015
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 9 | loss: 2.1658115
	speed: 0.0218s/iter; left time: 31.3356s
Epoch: 9 cost time: 1.8057842254638672
Epoch: 9, Steps: 128 | Train Loss: 1.9906909 Vali Loss: 1.8359360 Test Loss: 0.3965470
Validation loss decreased (1.835979 --> 1.835936).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 10 | loss: 2.0519397
	speed: 0.0220s/iter; left time: 28.7608s
Epoch: 10 cost time: 1.7849173545837402
Epoch: 10, Steps: 128 | Train Loss: 1.9907776 Vali Loss: 1.8349915 Test Loss: 0.3964846
Validation loss decreased (1.835936 --> 1.834991).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 11 | loss: 1.7712731
	speed: 0.0219s/iter; left time: 25.8504s
Epoch: 11 cost time: 1.785670280456543
Epoch: 11, Steps: 128 | Train Loss: 1.9900512 Vali Loss: 1.8358637 Test Loss: 0.3964821
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 12 | loss: 1.9593152
	speed: 0.0219s/iter; left time: 23.0258s
Epoch: 12 cost time: 1.8040602207183838
Epoch: 12, Steps: 128 | Train Loss: 1.9890331 Vali Loss: 1.8356910 Test Loss: 0.3965088
EarlyStopping counter: 2 out of 3
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 13 | loss: 1.9401628
	speed: 0.0220s/iter; left time: 20.3104s
Epoch: 13 cost time: 1.806124210357666
Epoch: 13, Steps: 128 | Train Loss: 1.9904572 Vali Loss: 1.8350779 Test Loss: 0.3965105
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_96_336_AdaCycle_ETTh2_ftM_sl96_pl336_bz64_lr0.0002_ljtype1_al0.35_dm256_dp0.1_tk10_wvdb1_m2_dfNone_itr1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (2545, 336, 7) (2545, 336, 7)
test shape: (2545, 336, 7) (2545, 336, 7)
mse:0.3964846134185791, mae:0.4115251898765564, rmse:0.629670262336731, mape:0.5520783066749573
